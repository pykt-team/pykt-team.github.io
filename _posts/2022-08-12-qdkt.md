---
layout: post
title: 'qDKT: Question-centric Deep Knowledge Tracing'
date: 2022-08-12T16:00:00.000+00:00
tags: model
categories: []
author: ''
post_image: "/assets/images/1_03.png"
post_format: ''
trending: true

---
We added qDKT into our pyKT package.

The link is [here](https://pykt-toolkit.readthedocs.io/en/latest/models.html#qdkt) and the API is [here](https://pykt-toolkit.readthedocs.io/en/latest/pykt.models.html#module-pykt.models.qdkt).

Original paper can be found at [Sonkar, Shashank, et al. “qdkt: Question-centric deep knowledge tracing.” arXiv preprint arXiv:2005.12442 (2020).](https://arxiv.org/pdf/2005.12442.pdf)

Title: qDKT: Question-centric Deep Knowledge Tracing

Author: [Shashank Sonkar](https://scholar.google.com/citations?user=4Rv56n4AAAAJ&hl=en&oi=ao), [Andrew E. Waters](https://scholar.google.com/citations?hl=en&user=Df_AQuwAAAAJ), [Andrew S. Lan](https://scholar.google.com/citations?hl=en&user=ZYc-LuMAAAAJ), [Phillip J. Grimaldi](https://scholar.google.com/citations?hl=en&user=pbSL_BcAAAAJ), [Richard G. Baraniuk](https://scholar.google.com/citations?user=N-BBA20AAAAJ&hl=en&oi=ao)

Abstract: Knowledge tracing (KT) models, e.g., the deep knowledge tracing (DKT) model, track an individual learner’s acquisition of skills over time by examining the learner’s performance on questions related to those skills. A practical limitation in most existing KT models is that all questions nested under a particular skill are treated as equivalent observations of a learner’s ability, which is an inaccurate assumption in real-world educational scenarios. To overcome this limitation we introduce qDKT, a variant of DKT that models every learner’s success probability on individual questions over time. First, qDKT incorporates graph Laplacian regularization to smooth predictions under each skill, which is particularly useful when the number of questions in the dataset is big. Second, qDKT uses an initialization scheme inspired by the fastText algorithm, which has found success in a variety of language modeling tasks. Our experiments on several real-world datasets show that qDKT achieves state-of-art performance on predicting learner outcomes. Because of this, qDKT can serve as a simple, yet tough-to-beat, baseline for new question-centric KT models.