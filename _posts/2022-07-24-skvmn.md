---
layout: post
title: 'SKVMN: Sequential Key-Value Memory Networks'
date: 2022-07-24T16:00:00.000+00:00
tags: model
categories: []
author: ''
post_image: 1_04.png
post_format: ''
trending: true

---
We added SKVMN into our pyKT package.

The link is [here](https://pykt-toolkit.readthedocs.io/en/latest/models.html#skvmn) and the API is [here](https://pykt-toolkit.readthedocs.io/en/latest/pykt.models.html#module-pykt.models.skvmn) .

Original paper can be found at [Abdelrahman, Ghodai, and Qing Wang. “Knowledge tracing with sequential key-value memory networks.” Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2019.](https://arxiv.org/pdf/1910.13197.pdf)

Title: Knowledge Tracing with Sequential Key-Value Memory Networks

Author: [Ghodai Abdelrahman](https://dl.acm.org/profile/99659451532), [Qing Wang](https://dl.acm.org/profile/81324494585)

Abstract: Can machines trace human knowledge like humans? Knowledge tracing (KT) is a fundamental task in a wide range of applications in education, such as massive open online courses (MOOCs), intelligent tutoring systems, educational games, and learning management systems. It models dynamics in a student’s knowledge states in relation to different learning concepts through their interactions with learning activities. Recently, several attempts have been made to use deep learning models for tackling the KT problem. Although these deep learning models have shown promising results, they have limitations: either lack the ability to go deeper to trace how specific concepts in a knowledge state are mastered by a student, or fail to capture long-term dependencies in an exercise sequence. In this paper, we address these limitations by proposing a novel deep learning model for knowledge tracing, namely Sequential Key-Value Memory Networks (SKVMN). This model unifies the strengths of recurrent modelling capacity and memory capacity of the existing deep learning KT models for modelling student learning. We have extensively evaluated our proposed model on five benchmark datasets. The experimental results show that (1) SKVMN outperforms the state-of-the-art KT models on all datasets, (2) SKVMN can better discover the correlation between latent concepts and questions, and (3) SKVMN can trace the knowledge state of students dynamics, and a leverage sequential dependencies in an exercise sequence for improved predication accuracy.